# Домашняя работа 2
## Реализация алгоритма DQN

( Посмотреть notebook **с рендерингом видео**:  [можно также здесь](https://nbviewer.org/github/eilyich/OtusHomework2/blob/master/homework.ipynb?flush_cache=true) )

В данной работе реализован алгоритм DQN в тестовой среде `LunarLander-v3`:
- выполнена подготовка среды
- реализована полносвязная нейросеть для ядра DQN
- реализованы функции реплей буфера и $\epsilon$-жадной стратегии
- реализован алгоритм оптимизации сети в двух версиях:
 - DQN с жестким обновлением target сети через n-эпизодов и MSE лосс функцией
 - DQN с мягким обновлением целевой сети, клиппингом градиентов и Huber лосс функцией
- выведены графики динамики обучения обоих алгоритмов
- выведена видео-запись действий "улучшенного" агента в последнем эпизоде обучения
